{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "92ecbd04",
   "metadata": {},
   "source": [
    "# Deep Neural Network for MNIST Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0b16d1f",
   "metadata": {},
   "source": [
    "## Import Relevant Packages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "200f2041",
   "metadata": {},
   "source": [
    "pip install tensorflow_datasets # install if not available in current library and restart kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "288a42a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\iolley2\\Anaconda3\\envs\\py3-TF2.0\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "import tensorflow_datasets as tfds # (import tensorflow data library containing 'mnist dataset')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60f18515",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c02e5043",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_dataset,mnist_info = tfds.load(name='mnist',\n",
    "                         as_supervised=True, # loads data in a 2-tuple structure [inputs,target]\n",
    "                         with_info=True # provides a tuple containing info about the version, features, # samples of the datasets)\n",
    "                         )\n",
    "# a datadet is often downloaded on the computer after the first load (for windows: c-drive/user/username/tensorflow_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "714d2055",
   "metadata": {},
   "source": [
    "### Extract the test and train dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e1af01de",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_train,mnist_test=mnist_dataset['train'],mnist_dataset['test']\n",
    "# No validation dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "615d60c5",
   "metadata": {},
   "source": [
    "### Extract validation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2725d66b",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_validation_samples = 0.1*mnist_info.splits['train'].num_examples # select 10% of training samples for validation\n",
    "num_validation_samples = tf.cast(num_validation_samples,tf.int64) #cast/convert the variable into an integer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "01adb5f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_test_samples = 0.1*mnist_info.splits['test'].num_examples\n",
    "num_test_samples = tf.cast(num_test_samples,tf.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "50e0bbf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale data\n",
    "def scale(image,label):\n",
    "    image = tf.cast(image,tf.float32)\n",
    "    image/=255.\n",
    "    return image,label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "54fb6d86",
   "metadata": {},
   "outputs": [],
   "source": [
    "scale_train_and_validation_data = mnist_train.map(scale)\n",
    "test_data = mnist_test.map(scale)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eba8351b",
   "metadata": {},
   "source": [
    "#### Shuffling data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "95bfeea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "BUFFER_SIZE=1000\n",
    "shuffled_train_and_validation_data = scale_train_and_validation_data.shuffle(BUFFER_SIZE)\n",
    "validation_data = shuffled_train_and_validation_data.take(num_validation_samples)\n",
    "train_data= shuffled_train_and_validation_data.skip(num_validation_samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3056274c",
   "metadata": {},
   "source": [
    "### Batching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "979fa4d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 100\n",
    "train_data = train_data.batch(BATCH_SIZE)\n",
    "validation_data=validation_data.batch(num_validation_samples)\n",
    "\n",
    "test_data = test_data.batch(BATCH_SIZE)\n",
    "\n",
    "validation_inputs,validation_targets=next(iter(validation_data))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f98c5f3c",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "746d72d1",
   "metadata": {},
   "source": [
    "### Outline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cf7c1782",
   "metadata": {},
   "outputs": [],
   "source": [
    "#784 input, 10 output, 2 hidden layer (50 nodes each)\n",
    "input_size = 784\n",
    "output_size = 10\n",
    "hidden_layer_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a39ae95b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    # Input layer\n",
    "    tf.keras.layers.Flatten(input_shape=(28,28,1)), # flattens/transforms tensor to a vector\n",
    "    # Hidden Layer\n",
    "    tf.keras.layers.Dense(hidden_layer_size,activation='relu'),\n",
    "    tf.keras.layers.Dense(hidden_layer_size,activation='relu'),\n",
    "    # Output Layer\n",
    "    tf.keras.layers.Dense(output_size,activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "733282ed",
   "metadata": {},
   "source": [
    "### Choose optimizer and loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "18ce406f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f3c44ea",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6dc34e24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "540/540 - 10s - loss: 0.3305 - accuracy: 0.9064 - val_loss: 0.1816 - val_accuracy: 0.9457 - 10s/epoch - 18ms/step\n",
      "Epoch 2/5\n",
      "540/540 - 5s - loss: 0.1359 - accuracy: 0.9604 - val_loss: 0.1274 - val_accuracy: 0.9625 - 5s/epoch - 10ms/step\n",
      "Epoch 3/5\n",
      "540/540 - 5s - loss: 0.0955 - accuracy: 0.9715 - val_loss: 0.1075 - val_accuracy: 0.9677 - 5s/epoch - 9ms/step\n",
      "Epoch 4/5\n",
      "540/540 - 5s - loss: 0.0719 - accuracy: 0.9783 - val_loss: 0.0958 - val_accuracy: 0.9710 - 5s/epoch - 9ms/step\n",
      "Epoch 5/5\n",
      "540/540 - 5s - loss: 0.0568 - accuracy: 0.9829 - val_loss: 0.0977 - val_accuracy: 0.9708 - 5s/epoch - 10ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x273d6bcbdc0>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NUM_EPOCHS = 5\n",
    "\n",
    "model.fit(train_data,epochs=NUM_EPOCHS,validation_data=(validation_inputs,validation_targets),verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "794fd8c3",
   "metadata": {},
   "source": [
    "1. At the beginning of the traininging loss will be set to zero\n",
    "2. The algorithm will iterate over a pre-set number of batches, all extracted from the training set\n",
    "3. The weights and biases will be updated as many times as there are batches\n",
    "4. We'll get a value for the lost function indicating how the training is going\n",
    "5. We'll also see a training accuracy\n",
    "6. At the end of the epoch, the algorithm will forward propagate the whole validation data set in a single batch through the optimized model and calculate the validation accuracy\n",
    "7. When we reach the maximum number of epochs, the training will be over"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "371ec017",
   "metadata": {},
   "source": [
    "## Test The Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ba0be8f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 1s 8ms/step - loss: 0.0833 - accuracy: 0.9742\n"
     ]
    }
   ],
   "source": [
    "test_loss,test_accuracy=model.evaluate(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e2def0ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Lodd: 0.08. Test accuracy: 97.42%\n"
     ]
    }
   ],
   "source": [
    "print('Test Lodd: {0:.2f}. Test accuracy: {1:.2f}%'.format(test_loss,test_accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "896e73e2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py3-TF2.0]",
   "language": "python",
   "name": "conda-env-py3-TF2.0-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
